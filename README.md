# PyTorch GPU Profiling: buenas y malas prÃ¡cticas

Este repositorio muestra **cÃ³mo perfilar cÃ³digo en PyTorch** y compara
implementaciones **ineficientes vs eficientes** cuando se trabaja con GPU.

El objetivo es entender:
- Por quÃ© **mezclar NumPy y GPU es mala idea**
- El impacto de **float64 vs float32**
- CÃ³mo evitar **copias CPU â†” GPU**
- CÃ³mo usar correctamente `torch.autograd.profiler`

---

## ğŸš€ QuÃ© se aprende

âœ” Uso de `torch.autograd.profiler`  
âœ” Etiquetado de secciones con `record_function`  
âœ” Coste oculto de `.cpu()`, `.numpy()` y `.item()`  
âœ” Diferencias entre `float64` y `float32` en GPU  
âœ” Uso correcto de `nonzero` en PyTorch  
âœ” Por quÃ© los tensores grandes pueden causar **CUDA out of memory**

---

ğŸ§© Requisitos

Antes de ejecutar el script, instala las dependencias:

pip install -r requirements.txt

ğŸ§‘â€ğŸ’» Autor

Desarrollado por Gus como parte de su aprendizaje en Python e IA.
